{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d8c529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/rahul/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrahul-e-dev\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.rdBase import BlockLogs\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "from utils import standardize, get_scaffold\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from chemprop.featurizers.molgraph.reaction import CondensedGraphOfReactionFeaturizer\n",
    "from chemprop.data.datapoints import ReactionDatapoint\n",
    "from chemprop.data.datasets import Datum\n",
    "\n",
    "import lightning as L\n",
    "from chemprop.data.collate import collate_batch\n",
    "from chemprop.data.dataloader import build_dataloader\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "load_dotenv('.env.secret')\n",
    "wandb.login(key=os.environ['WANDB_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2f7fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_to_inchi(mol):\n",
    "    with BlockLogs():\n",
    "        return Chem.MolToInchi(mol)\n",
    "\n",
    "df = pd.read_csv(\"./GSK_HepG2.csv\")\n",
    "df = df.iloc[:, 1:]\n",
    "df.columns = ['smiles', 'per_inhibition']\n",
    "df['per_inhibition'] = -df['per_inhibition']\n",
    "\n",
    "\n",
    "# standardize and convert to inchi\n",
    "df['mol'] = df['smiles'].map(standardize)\n",
    "df = df.dropna(subset=['mol'])\n",
    "df['inchi'] = df['mol'].map(mol_to_inchi)\n",
    "df = df.groupby([\"inchi\"]).filter(lambda x: len(x) == 1).reset_index(drop=True)\n",
    "\n",
    "clusters, _ = pd.factorize(\n",
    "    df['mol']\n",
    "        .map(Chem.MolToSmiles) # type: ignore\n",
    "        .map(get_scaffold)\n",
    ")\n",
    "clusters = pd.Series(clusters)\n",
    "\n",
    "\n",
    "df = df.drop(['smiles', 'inchi'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ef6a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=1, random_state=RANDOM_SEED)\n",
    "train_idxs, val_test_idxs = next(splitter.split(df, groups=clusters))\n",
    "df_train = df.loc[train_idxs].reset_index(drop=True)\n",
    "df_val_test = df.loc[val_test_idxs].reset_index(drop=True)\n",
    "clusters_val_test = clusters.iloc[val_test_idxs].reset_index(drop=True)\n",
    "\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, random_state=RANDOM_SEED, test_size=0.5)\n",
    "val_idxs, test_idxs = next(splitter.split(df_val_test, groups=clusters_val_test))\n",
    "df_val = df_val_test.loc[val_idxs].reset_index(drop=True)\n",
    "df_test = df_val_test.loc[test_idxs].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c454b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExemplarDataset(Dataset):\n",
    "    def __init__(self, df_train_exemplars, df_val):\n",
    "        self.df_train_exemplars = df_train_exemplars.reset_index(drop=True)\n",
    "        self.df_val = df_val\n",
    "        self.featurizer = CondensedGraphOfReactionFeaturizer()\n",
    "        self.pairs = [\n",
    "            (i, j)\n",
    "            for i in range(len(self.df_val))\n",
    "            for j in range(len(self.df_train_exemplars))\n",
    "        ]\n",
    "\n",
    "    def prepare_datum(self, lidx, ridx):\n",
    "        left_mol = self.df_val['mol'][lidx]\n",
    "        right_mol = self.df_train_exemplars['mol'][ridx]\n",
    "        delta = (\n",
    "            self.df_val['per_inhibition'][lidx] > self.df_train_exemplars['per_inhibition'][ridx]\n",
    "        ).astype(float)\n",
    "\n",
    "        mg = self.featurizer((left_mol, right_mol), None, None)\n",
    "        rxn_dp = ReactionDatapoint(left_mol, right_mol, np.array([delta]))\n",
    "        return Datum(mg, None, None, np.array([delta]), rxn_dp.weight, rxn_dp.lt_mask, rxn_dp.gt_mask)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i, j = self.pairs[idx]\n",
    "        return self.prepare_datum(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca941441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from chemprop import data, featurizers, models, nn\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoint_reference = 'rahul-e-dev/chemprop_delta_clf/model-t8zqdbql:v4'\n",
    "wandb_logger = WandbLogger(project=\"chemprop_delta_clf\")\n",
    "artifact_dir = wandb_logger.download_artifact(checkpoint_reference, artifact_type=\"model\")\n",
    "mpnn = models.MPNN.load_from_checkpoint(Path(artifact_dir) / \"model.ckpt\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27bc262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e4dc0d811742ff9678fd5eccc1b290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exemplar_ds = ExemplarDataset(\n",
    "    df_train[df_train['per_inhibition'] > 0].sample(50).reset_index(drop=True),\n",
    "    df_val\n",
    ")\n",
    "\n",
    "exemplar_dl = build_dataloader(\n",
    "    exemplar_ds,\n",
    "    batch_size=2048,\n",
    "    num_workers=4,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_ds_preds = trainer.predict(model=mpnn, dataloaders=exemplar_dl)\n",
    "val_ds_preds = torch.cat(val_ds_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cdcb3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "asd = defaultdict(list)\n",
    "for (i, j), delta in zip(exemplar_ds.pairs, val_ds_preds.squeeze()):\n",
    "    exemplar_val = exemplar_ds.df_train_exemplars['per_inhibition'][j]\n",
    "    asd[i].append(float(delta.item()))\n",
    "\n",
    "\n",
    "df_val['diffs'] = asd\n",
    "df_val['pred'] = df_val['diffs'].map(np.median) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5491331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['true'] = df_val['per_inhibition'] > -15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59d08f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29036004645760743"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(df_val['true'], df_val['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b47f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaffe06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
