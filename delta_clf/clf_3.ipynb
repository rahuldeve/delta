{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2befbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from chemprop import data, featurizers, models, nn\n",
    "from data import ConstrastiveDataModule, ExemplarDataset\n",
    "from dotenv import load_dotenv\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import wandb\n",
    "from commons.data import load_and_split_gsk_dataset\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seeds(RANDOM_SEED)\n",
    "\n",
    "load_dotenv('.env.secret')\n",
    "wandb.login(key='cf344975eb80edf6f0d52af80528cc6094234caf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = load_and_split_gsk_dataset(\"../GSK_HepG2.csv\", RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09fd022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop.conf import DEFAULT_HIDDEN_DIM\n",
    "from chemprop.nn.ffn import MLP\n",
    "from chemprop.nn.metrics import BCELoss, BinaryAUPRC, ChempropMetric\n",
    "from chemprop.nn.predictors import Predictor, PredictorRegistry\n",
    "from chemprop.nn.transforms import UnscaleTransform\n",
    "from chemprop.utils import Factory\n",
    "from lightning.pytorch.core.mixins import HyperparametersMixin\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "@PredictorRegistry.register(\"ranking\")\n",
    "class RankNetPredictor(Predictor, HyperparametersMixin):\n",
    "\n",
    "    n_targets = 1\n",
    "    _T_default_criterion = BCELoss\n",
    "    _T_default_metric = BinaryAUPRC\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_tasks: int = 1,\n",
    "        input_dim: int = DEFAULT_HIDDEN_DIM,\n",
    "        hidden_dim: int = 300,\n",
    "        n_layers: int = 1,\n",
    "        dropout: float = 0.0,\n",
    "        activation: str | torch.nn.Module = \"relu\",\n",
    "        criterion: ChempropMetric | None = None,\n",
    "        task_weights: Tensor | None = None,\n",
    "        threshold: float | None = None,\n",
    "        output_transform: UnscaleTransform | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # manually add criterion and output_transform to hparams to suppress lightning's warning\n",
    "        # about double saving their state_dict values.\n",
    "        ignore_list = [\"criterion\", \"output_transform\", \"activation\"]\n",
    "        self.save_hyperparameters(ignore=ignore_list)\n",
    "        self.hparams[\"criterion\"] = criterion\n",
    "        self.hparams[\"output_transform\"] = output_transform\n",
    "        self.hparams[\"activation\"] = activation\n",
    "        self.hparams[\"cls\"] = self.__class__\n",
    "\n",
    "        self.ffn = MLP.build(\n",
    "            input_dim, n_tasks * self.n_targets, hidden_dim, n_layers, dropout, activation\n",
    "        )\n",
    "        task_weights = torch.ones(n_tasks) if task_weights is None else task_weights\n",
    "        self.criterion = criterion or Factory.build(\n",
    "            self._T_default_criterion, task_weights=task_weights, threshold=threshold\n",
    "        )\n",
    "        self.output_transform = output_transform if output_transform is not None else torch.nn.Identity()\n",
    "\n",
    "    @property\n",
    "    def input_dim(self) -> int:\n",
    "        return self.ffn.input_dim\n",
    "\n",
    "    @property\n",
    "    def output_dim(self) -> int:\n",
    "        return self.ffn.output_dim\n",
    "\n",
    "    @property\n",
    "    def n_tasks(self) -> int:\n",
    "        return self.output_dim // self.n_targets\n",
    "\n",
    "    def forward(self, Z: Tensor) -> Tensor:\n",
    "        # print(Z.shape)\n",
    "        A, B = torch.split(Z, self.input_dim, dim=-1)\n",
    "        logit_A = self.ffn(A)\n",
    "        logit_B = self.ffn(B)\n",
    "        return (logit_A - logit_B).sigmoid()\n",
    "\n",
    "    def encode(self, Z: Tensor, i: int) -> Tensor:\n",
    "        A, B = torch.split(Z, self.input_dim, dim=-1)\n",
    "        enc_A = self.ffn[:i](A)\n",
    "        enc_B = self.ffn[:i](B)\n",
    "        return torch.cat([enc_A, enc_B], dim=-1)\n",
    "    \n",
    "    def train_step(self, Z: Tensor) -> Tensor:\n",
    "        # print(Z.shape)\n",
    "        A, B = torch.split(Z, self.input_dim, dim=-1)\n",
    "        logit_A = self.ffn(A)\n",
    "        logit_B = self.ffn(B)\n",
    "        return logit_A - logit_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53dcdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdims = featurizers.SimpleMoleculeMolGraphFeaturizer().shape # the dimensions of the featurizer, given as (atom_dims, bond_dims).\n",
    "mcmp = nn.MulticomponentMessagePassing(\n",
    "    blocks=[nn.BondMessagePassing(*fdims)],\n",
    "    n_components=2,\n",
    "    shared=True\n",
    ")\n",
    "agg = nn.NormAggregation()\n",
    "ffn = RankNetPredictor(n_tasks=1, input_dim=mcmp.output_dim // 2)\n",
    "batch_norm = True\n",
    "metric_list = [nn.metrics.BinaryF1Score(), nn.metrics.BinaryAUPRC(), nn.metrics.BinaryAUROC()]\n",
    "mpnn = models.multi.MulticomponentMPNN(mcmp, agg, ffn, batch_norm, metric_list)\n",
    "mpnn.max_lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151275e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "wandb_logger = WandbLogger(project=\"chemprop_delta_clf\", log_model=\"all\", save_code=True)\n",
    "wandb_logger.experiment.mark_preempting()\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    logger=wandb_logger,\n",
    "    enable_checkpointing=True,  # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=50,  # number of epochs to train for\n",
    "    reload_dataloaders_every_n_epochs=1,\n",
    "    log_every_n_steps=50,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=True, patience=10),\n",
    "        ModelCheckpoint(monitor=\"val_loss\", mode=\"min\", save_top_k=2)\n",
    "    ]\n",
    ")\n",
    "\n",
    "contrastive_data_module = ConstrastiveDataModule(df_train, df_val)\n",
    "trainer.fit(mpnn, datamodule=contrastive_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed18bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = wandb_logger.experiment.id\n",
    "checkpoint_reference = f\"rahul-e-dev/chemprop_delta_clf/model-{run_id}:best\"\n",
    "artifact_dir = wandb_logger.download_artifact(checkpoint_reference, artifact_type=\"model\")\n",
    "\n",
    "\n",
    "ckpt = torch.load(Path(artifact_dir) / \"model.ckpt\", map_location='cpu', weights_only=False)\n",
    "hparams = ckpt.get('hyper_parameters', ckpt.get('hparams', {}))\n",
    "mpnn.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3927e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplar_df = df_train[df_train['per_inhibition'] >= -20].sample(100).reset_index(drop=True)\n",
    "\n",
    "exemplar_ds = ExemplarDataset(\n",
    "    df_test,\n",
    "    exemplar_df\n",
    ")\n",
    "\n",
    "exemplar_dl = DataLoader(\n",
    "    dataset=exemplar_ds,\n",
    "    batch_size=2048,\n",
    "    shuffle=False,\n",
    "    collate_fn=data.dataloader.collate_multicomponent,\n",
    "    num_workers=12,\n",
    ")\n",
    "\n",
    "test_ds_preds = trainer.predict(model=mpnn, dataloaders=exemplar_dl)\n",
    "test_ds_preds = torch.cat(test_ds_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd1b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def calc(x):\n",
    "    x = np.array(x)\n",
    "    return (x>=0.5).sum()\n",
    "\n",
    "\n",
    "deltas = defaultdict(list)\n",
    "for (i, j), delta in zip(exemplar_ds.pairs, test_ds_preds.squeeze()):\n",
    "    deltas[i].append(float(delta.item()))\n",
    "\n",
    "\n",
    "df_test['deltas'] = deltas\n",
    "df_test['pred_probs'] = df_test['deltas'].map(calc)\n",
    "df_test['means'] = df_test['deltas'].map(np.mean)\n",
    "df_test['std'] = df_test['deltas'].map(np.std)\n",
    "df_test['range'] = df_test['deltas'].map(lambda x: max(x) - min(x))\n",
    "df_test['preds'] = df_test['pred_probs'] >= 10\n",
    "df_test['true'] = df_test['per_inhibition'] >= -15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "wandb_logger.log_table(\n",
    "    'final_metrics', \n",
    "    ['f1', 'precision', 'recall', 'accuracy'],\n",
    "    [[\n",
    "        f1_score(df_test['true'], df_test['preds']),\n",
    "        precision_score(df_test['true'], df_test['preds']),\n",
    "        recall_score(df_test['true'], df_test['preds']),\n",
    "        accuracy_score(df_test['true'], df_test['preds'])\n",
    "    ]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88695fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a61707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
