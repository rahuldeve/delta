{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2befbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.rdBase import BlockLogs\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "from utils import standardize, get_scaffold\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from chemprop.featurizers.molgraph.reaction import CondensedGraphOfReactionFeaturizer\n",
    "from chemprop.data.datapoints import ReactionDatapoint\n",
    "from chemprop.data.datasets import Datum\n",
    "\n",
    "import lightning as L\n",
    "from chemprop.data.collate import collate_batch\n",
    "from chemprop.data.dataloader import build_dataloader\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "load_dotenv('.env.secret')\n",
    "wandb.login(key=os.environ['WANDB_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f70809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_to_inchi(mol):\n",
    "    with BlockLogs():\n",
    "        return Chem.MolToInchi(mol)\n",
    "\n",
    "df = pd.read_csv(\"./GSK_HepG2.csv\")\n",
    "df = df.iloc[:, 1:]\n",
    "df.columns = ['smiles', 'per_inhibition']\n",
    "df['per_inhibition'] = -df['per_inhibition']\n",
    "\n",
    "\n",
    "# standardize and convert to inchi\n",
    "df['mol'] = df['smiles'].map(standardize)\n",
    "df = df.dropna(subset=['mol'])\n",
    "df['inchi'] = df['mol'].map(mol_to_inchi)\n",
    "df = df.groupby([\"inchi\"]).filter(lambda x: len(x) == 1).reset_index(drop=True)\n",
    "\n",
    "clusters, _ = pd.factorize(\n",
    "    df['mol']\n",
    "        .map(Chem.MolToSmiles) # type: ignore\n",
    "        .map(get_scaffold)\n",
    ")\n",
    "clusters = pd.Series(clusters)\n",
    "\n",
    "\n",
    "df = df.drop(['smiles', 'inchi'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c794f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=1, random_state=RANDOM_SEED)\n",
    "train_idxs, val_test_idxs = next(splitter.split(df, groups=clusters))\n",
    "df_train = df.loc[train_idxs].reset_index(drop=True)\n",
    "df_val_test = df.loc[val_test_idxs].reset_index(drop=True)\n",
    "clusters_val_test = clusters.iloc[val_test_idxs].reset_index(drop=True)\n",
    "\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, random_state=RANDOM_SEED, test_size=0.5)\n",
    "val_idxs, test_idxs = next(splitter.split(df_val_test, groups=clusters_val_test))\n",
    "df_val = df_val_test.loc[val_idxs].reset_index(drop=True)\n",
    "df_test = df_val_test.loc[test_idxs].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d03840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffledPairsDataset(Dataset):\n",
    "    def __init__(self, data, sample_ratio=5):\n",
    "        self.data = data  # raw data\n",
    "        self.featurizer = CondensedGraphOfReactionFeaturizer()\n",
    "        self.pairs = []\n",
    "        self.sample_ratio = sample_ratio\n",
    "        self.update_pairs()  # list of (i, j, label)\n",
    "\n",
    "    def update_pairs(self):\n",
    "        N = len(self.data)\n",
    "        pairs = [\n",
    "            (i, random.randint(0, N-1))\n",
    "            for i in range(N)\n",
    "            for _ in range(self.sample_ratio)\n",
    "        ]\n",
    "\n",
    "        pairs += [(j, i) for i,j in pairs]\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def prepare_datum(self, lidx, ridx):\n",
    "        left_mol = self.data['mol'][lidx]\n",
    "        right_mol = self.data['mol'][ridx]\n",
    "        delta = (\n",
    "            self.data['per_inhibition'][lidx] > self.data['per_inhibition'][ridx]\n",
    "        ).astype(float)\n",
    "\n",
    "        mg = self.featurizer((left_mol, right_mol), None, None)\n",
    "        rxn_dp = ReactionDatapoint(left_mol, right_mol, np.array([delta]))\n",
    "        return Datum(mg, None, None, np.array([delta]), rxn_dp.weight, rxn_dp.lt_mask, rxn_dp.gt_mask)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i, j = self.pairs[idx]\n",
    "        return self.prepare_datum(i, j)\n",
    "    \n",
    "\n",
    "class ExemplarDataset(Dataset):\n",
    "    def __init__(self, df_train_exemplars, df_val):\n",
    "        self.df_train_exemplars = df_train_exemplars.reset_index(drop=True)\n",
    "        self.df_val = df_val\n",
    "        self.featurizer = CondensedGraphOfReactionFeaturizer()\n",
    "        self.pairs = [\n",
    "            (i, j)\n",
    "            for i in range(len(self.df_val))\n",
    "            for j in range(len(self.df_train_exemplars))\n",
    "        ]\n",
    "\n",
    "    def prepare_datum(self, lidx, ridx):\n",
    "        left_mol = self.df_val['mol'][lidx]\n",
    "        right_mol = self.df_train_exemplars['mol'][ridx]\n",
    "        delta = (\n",
    "            self.df_val['per_inhibition'][lidx] > self.df_train_exemplars['per_inhibition'][ridx]\n",
    "        ).astype(float)\n",
    "\n",
    "        mg = self.featurizer((left_mol, right_mol), None, None)\n",
    "        rxn_dp = ReactionDatapoint(left_mol, right_mol, np.array([delta]))\n",
    "        return Datum(mg, None, None, np.array([delta]), rxn_dp.weight, rxn_dp.lt_mask, rxn_dp.gt_mask)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i, j = self.pairs[idx]\n",
    "        return self.prepare_datum(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1525a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ShuffledPairsDataset(df_train, sample_ratio=10)\n",
    "\n",
    "exemplar_df = pd.concat([\n",
    "    df_train[df_train['per_inhibition'] > 0].sample(25),\n",
    "    df_train[df_train['per_inhibition'] < 0].sample(25)\n",
    "])\n",
    "\n",
    "val_ds = ExemplarDataset(\n",
    "    exemplar_df.reset_index(drop=True),\n",
    "    df_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac066253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstrastiveDataModule(L.LightningDataModule):\n",
    "    def __init__(self, train_dataset: ShuffledPairsDataset, val_dataset: ExemplarDataset):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        self.train_dataset.update_pairs()\n",
    "        return build_dataloader(\n",
    "            self.train_dataset,   # type: ignore\n",
    "            batch_size=1024,\n",
    "            num_workers=12,\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        exemplar_df = pd.concat([\n",
    "            df_train[df_train['per_inhibition'] > 0].sample(25),\n",
    "            df_train[df_train['per_inhibition'] < 0].sample(25)\n",
    "        ])\n",
    "\n",
    "        val_ds = ExemplarDataset(\n",
    "            exemplar_df.reset_index(drop=True),\n",
    "            df_val\n",
    "        )\n",
    "        self.val_dataset = val_ds\n",
    "        return build_dataloader(\n",
    "            self.val_dataset,   # type: ignore\n",
    "            batch_size=2048,\n",
    "            num_workers=12,\n",
    "            shuffle=False\n",
    "        )\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        # for some reason, pytorch lightning does not like using build_dataloader function here\n",
    "        # manually creating the dataloader for now\n",
    "        return DataLoader(\n",
    "            self.val_dataset,   # type: ignore\n",
    "            collate_fn=collate_batch,\n",
    "            batch_size=1024,\n",
    "            num_workers=12,\n",
    "            shuffle=False,\n",
    "            drop_last=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53dcdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop import data, featurizers, models, nn\n",
    "\n",
    "fdims = train_ds.featurizer.shape # the dimensions of the featurizer, given as (atom_dims, bond_dims).\n",
    "mp = nn.BondMessagePassing(*fdims)\n",
    "agg = nn.NormAggregation()\n",
    "ffn = nn.BinaryClassificationFFN(n_tasks=1)\n",
    "batch_norm = True\n",
    "metric_list = [nn.metrics.BinaryF1Score(), nn.metrics.BinaryAUPRC(), nn.metrics.BinaryAUROC()]\n",
    "mpnn = models.MPNN(mp, agg, ffn, batch_norm, metric_list)\n",
    "# mpnn.max_lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151275e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "wandb.finish()\n",
    "wandb_logger = WandbLogger(project=\"chemprop_delta_clf\", log_model=\"all\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    logger=wandb_logger,\n",
    "    enable_checkpointing=True,  # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=20,  # number of epochs to train for\n",
    "    reload_dataloaders_every_n_epochs=1,\n",
    "    log_every_n_steps=50,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val/prc\", mode=\"max\", verbose=True, patience=10),\n",
    "        ModelCheckpoint(monitor=\"val/prc\", mode=\"max\", save_top_k=2)\n",
    "    ]\n",
    ")\n",
    "\n",
    "contrastive_data_module = ConstrastiveDataModule(train_ds, val_ds)\n",
    "trainer.fit(mpnn, datamodule=contrastive_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3927e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "run_id = wandb_logger.experiment.id\n",
    "checkpoint_reference = f\"rahul-e-dev/chemprop_delta_clf/model-{run_id}:best\"\n",
    "artifact_dir = wandb_logger.download_artifact(checkpoint_reference, artifact_type=\"model\")\n",
    "mpnn = models.MPNN.load_from_checkpoint(\n",
    "    Path(artifact_dir) / \"model.ckpt\"\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    ")\n",
    "\n",
    "exemplar_df = df_train[df_train['per_inhibition'] > -15].sample(100)\n",
    "\n",
    "exemplar_ds = ExemplarDataset(\n",
    "    exemplar_df.reset_index(drop=True),\n",
    "    df_val\n",
    ")\n",
    "\n",
    "exemplar_dl = build_dataloader(\n",
    "    exemplar_ds,\n",
    "    batch_size=2048,\n",
    "    num_workers=4,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_ds_preds = trainer.predict(model=mpnn, dataloaders=exemplar_dl)\n",
    "val_ds_preds = torch.cat(val_ds_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd1b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def calc(x):\n",
    "    x = np.array(x)\n",
    "    return (x>0.5).sum()\n",
    "\n",
    "\n",
    "deltas = defaultdict(list)\n",
    "for (i, j), delta in zip(exemplar_ds.pairs, val_ds_preds.squeeze()):\n",
    "    exemplar_val = exemplar_ds.df_train_exemplars['per_inhibition'][j]\n",
    "    deltas[i].append(float(delta.item()))\n",
    "\n",
    "\n",
    "df_val['deltas'] = deltas\n",
    "df_val['pred_probs'] = df_val['deltas'].map(calc)\n",
    "df_val['asd'] = df_val['deltas'].map(sum)\n",
    "df_val['preds'] = df_val['pred_probs'] > 10\n",
    "df_val['true'] = df_val['per_inhibition'] > -15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "wandb_logger.log_table(\n",
    "    'final_metrics', \n",
    "    ['f1', 'precision', 'recall', 'accuracy'],\n",
    "    [[\n",
    "        f1_score(df_val['true'], df_val['preds']),\n",
    "        precision_score(df_val['true'], df_val['preds']),\n",
    "        recall_score(df_val['true'], df_val['preds']),\n",
    "        accuracy_score(df_val['true'], df_val['preds'])\n",
    "    ]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88695fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
