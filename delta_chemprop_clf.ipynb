{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2befbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.rdBase import BlockLogs\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "from utils import standardize, get_scaffold\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "import random\n",
    "from chemprop.featurizers.molgraph.reaction import CondensedGraphOfReactionFeaturizer\n",
    "from chemprop.data.datapoints import ReactionDatapoint\n",
    "from chemprop.data.datasets import Datum\n",
    "\n",
    "import lightning as L\n",
    "from chemprop.data.collate import collate_batch\n",
    "from chemprop.data.dataloader import build_dataloader\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "load_dotenv('.env.secret')\n",
    "wandb.login(key=os.environ['WANDB_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f70809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_to_inchi(mol):\n",
    "    with BlockLogs():\n",
    "        return Chem.MolToInchi(mol)\n",
    "\n",
    "df = pd.read_csv(\"./GSK_HepG2.csv\")\n",
    "df = df.iloc[:, 1:]\n",
    "df.columns = ['smiles', 'per_inhibition']\n",
    "df['per_inhibition'] = -df['per_inhibition']\n",
    "\n",
    "\n",
    "# standardize and convert to inchi\n",
    "df['mol'] = df['smiles'].map(standardize)\n",
    "df = df.dropna(subset=['mol'])\n",
    "df['inchi'] = df['mol'].map(mol_to_inchi)\n",
    "df = df.groupby([\"inchi\"]).filter(lambda x: len(x) == 1).reset_index(drop=True)\n",
    "\n",
    "clusters, _ = pd.factorize(\n",
    "    df['mol']\n",
    "        .map(Chem.MolToSmiles) # type: ignore\n",
    "        .map(get_scaffold)\n",
    ")\n",
    "clusters = pd.Series(clusters)\n",
    "\n",
    "\n",
    "df = df.drop(['smiles', 'inchi'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c794f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=1, random_state=RANDOM_SEED)\n",
    "train_idxs, val_test_idxs = next(splitter.split(df, groups=clusters))\n",
    "df_train = df.loc[train_idxs].reset_index(drop=True)\n",
    "df_val_test = df.loc[val_test_idxs].reset_index(drop=True)\n",
    "clusters_val_test = clusters.iloc[val_test_idxs].reset_index(drop=True)\n",
    "\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, random_state=RANDOM_SEED, test_size=0.5)\n",
    "val_idxs, test_idxs = next(splitter.split(df_val_test, groups=clusters_val_test))\n",
    "df_val = df_val_test.loc[val_idxs].reset_index(drop=True)\n",
    "df_test = df_val_test.loc[test_idxs].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d03840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffledPairsDataset(Dataset):\n",
    "    def __init__(self, data, sample_ratio=5):\n",
    "        self.data = data  # raw data\n",
    "        self.featurizer = CondensedGraphOfReactionFeaturizer()\n",
    "        self.pairs = []\n",
    "        self.sample_ratio = sample_ratio\n",
    "        self.update_pairs()  # list of (i, j, label)\n",
    "\n",
    "    def update_pairs(self):\n",
    "        N = len(self.data)\n",
    "        pairs = [\n",
    "            (i, random.randint(0, N-1))\n",
    "            for i in range(N)\n",
    "            for _ in range(self.sample_ratio)\n",
    "        ]\n",
    "\n",
    "        pairs += [(j, i) for i,j in pairs]\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def prepare_datum(self, lidx, ridx):\n",
    "        left_mol = self.data['mol'][lidx]\n",
    "        right_mol = self.data['mol'][ridx]\n",
    "        delta = (\n",
    "            self.data['per_inhibition'][lidx] > self.data['per_inhibition'][ridx]\n",
    "        ).astype(float)\n",
    "\n",
    "        mg = self.featurizer((left_mol, right_mol), None, None)\n",
    "        rxn_dp = ReactionDatapoint(left_mol, right_mol, np.array([delta]))\n",
    "        return Datum(mg, None, None, np.array([delta]), rxn_dp.weight, rxn_dp.lt_mask, rxn_dp.gt_mask)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i, j = self.pairs[idx]\n",
    "        return self.prepare_datum(i, j)\n",
    "    \n",
    "\n",
    "class ExemplarDataset(Dataset):\n",
    "    def __init__(self, df_train_exemplars, df_val):\n",
    "        self.df_train_exemplars = df_train_exemplars.reset_index(drop=True)\n",
    "        self.df_val = df_val\n",
    "        self.featurizer = CondensedGraphOfReactionFeaturizer()\n",
    "        self.pairs = [\n",
    "            (i, j)\n",
    "            for i in range(len(self.df_val))\n",
    "            for j in range(len(self.df_train_exemplars))\n",
    "        ]\n",
    "\n",
    "    def prepare_datum(self, lidx, ridx):\n",
    "        left_mol = self.df_val['mol'][lidx]\n",
    "        right_mol = self.df_train_exemplars['mol'][ridx]\n",
    "        delta = (\n",
    "            self.df_val['per_inhibition'][lidx] > self.df_train_exemplars['per_inhibition'][ridx]\n",
    "        ).astype(float)\n",
    "\n",
    "        mg = self.featurizer((left_mol, right_mol), None, None)\n",
    "        rxn_dp = ReactionDatapoint(left_mol, right_mol, np.array([delta]))\n",
    "        return Datum(mg, None, None, np.array([delta]), rxn_dp.weight, rxn_dp.lt_mask, rxn_dp.gt_mask)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i, j = self.pairs[idx]\n",
    "        return self.prepare_datum(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1525a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ShuffledPairsDataset(df_train, sample_ratio=5)\n",
    "val_ds = ExemplarDataset(\n",
    "    df_train.sample(10).reset_index(drop=True),\n",
    "    df_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac066253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstrastiveDataModule(L.LightningDataModule):\n",
    "    def __init__(self, train_dataset: ShuffledPairsDataset, val_dataset: ExemplarDataset):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        self.train_dataset.update_pairs()\n",
    "        return build_dataloader(\n",
    "            self.train_dataset,   # type: ignore\n",
    "            batch_size=512,\n",
    "            num_workers=4,\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        self.val_dataset = ExemplarDataset(\n",
    "            self.train_dataset.data.sample(10).reset_index(drop=True),\n",
    "            self.val_dataset.df_val\n",
    "        )\n",
    "        return build_dataloader(\n",
    "            self.val_dataset,   # type: ignore\n",
    "            batch_size=2048,\n",
    "            num_workers=4,\n",
    "            shuffle=False\n",
    "        )\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        # for some reason, pytorch lightning does not like using build_dataloader function here\n",
    "        # manually creating the dataloader for now\n",
    "        return DataLoader(\n",
    "            self.val_dataset,   # type: ignore\n",
    "            collate_fn=collate_batch,\n",
    "            batch_size=512,\n",
    "            num_workers=4,\n",
    "            shuffle=False,\n",
    "            drop_last=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53dcdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop import data, featurizers, models, nn\n",
    "\n",
    "fdims = train_ds.featurizer.shape # the dimensions of the featurizer, given as (atom_dims, bond_dims).\n",
    "mp = nn.BondMessagePassing(*fdims)\n",
    "agg = nn.NormAggregation()\n",
    "ffn = nn.BinaryClassificationFFN(n_tasks=1)\n",
    "batch_norm = True\n",
    "metric_list = [nn.metrics.BinaryF1Score(), nn.metrics.BinaryAUPRC(), nn.metrics.BinaryAUROC()]\n",
    "mpnn = models.MPNN(mp, agg, ffn, batch_norm, metric_list)\n",
    "mpnn.max_lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151275e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"chemprop_delta_clf\", log_model=\"all\")\n",
    "trainer = L.Trainer(\n",
    "    logger=wandb_logger,\n",
    "    enable_checkpointing=True,  # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=20,  # number of epochs to train for\n",
    "    reload_dataloaders_every_n_epochs=1,\n",
    "    log_every_n_steps=50,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val/f1\", mode=\"max\", verbose=True, patience=5),\n",
    "        ModelCheckpoint(monitor=\"val/f1\", mode=\"max\", save_top_k=2)\n",
    "    ]\n",
    ")\n",
    "\n",
    "contrastive_data_module = ConstrastiveDataModule(train_ds, val_ds)\n",
    "trainer.fit(mpnn, datamodule=contrastive_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add0b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplar_ds = ExemplarDataset(\n",
    "    df_train.sample(25).reset_index(drop=True),\n",
    "    df_val\n",
    ")\n",
    "\n",
    "exemplar_dl = build_dataloader(\n",
    "    exemplar_ds,\n",
    "    batch_size=2048,\n",
    "    num_workers=4,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12465f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds_preds = trainer.predict(dataloaders=exemplar_dl)\n",
    "val_ds_preds = torch.cat(val_ds_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad776b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "exemplar_ds = contrastive_data_module.val_dataset\n",
    "asd = defaultdict(list)\n",
    "for (i, j), delta in zip(exemplar_ds.pairs, val_ds_preds.squeeze()):\n",
    "    exemplar_val = exemplar_ds.df_train_exemplars['per_inhibition'][j]\n",
    "    asd[i].append(float(delta.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db3f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "qqq = [\n",
    "    (k, statistics.mean(v))\n",
    "    for k, v in asd.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa67ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['pred'] = [x for _, x in qqq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881d2ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.to_csv('qqq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.sort_values(by='per_inhibition')[::-1].to_csv('qqq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eccebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd1806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79180a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4f7196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = [\n",
    "    (f\"{i}_exemplar\", {\"type\": \"exemplar\"})\n",
    "    for i in range(len(exemplar_ds.df_train_exemplars))\n",
    "]\n",
    "\n",
    "node_list += [\n",
    "    (f\"{i}_regular\", {\"type\": \"regular\"})\n",
    "    for i in range(len(exemplar_ds.df_val))\n",
    "]\n",
    "\n",
    "edge_list = []\n",
    "for (i, j), delta in zip(exemplar_ds.pairs, val_ds_preds.squeeze()):\n",
    "    if delta.item() > 0.5:\n",
    "        edge_list.append((\n",
    "            f\"{i}_regular\", \n",
    "            f\"{j}_exemplar\", \n",
    "            delta.item()\n",
    "        ))\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(node_list)\n",
    "G.add_weighted_edges_from(edge_list)\n",
    "nx.write_gexf(G, 'asd.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3927e3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd1b6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
