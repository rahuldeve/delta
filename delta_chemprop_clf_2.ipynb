{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2befbca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/rahul/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrahul-e-dev\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.rdBase import BlockLogs\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "from utils import standardize, get_scaffold\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "from chemprop import data, featurizers, models, nn\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seeds(RANDOM_SEED)\n",
    "\n",
    "load_dotenv('.env.secret')\n",
    "wandb.login(key=os.environ['WANDB_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f70809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_to_inchi(mol):\n",
    "    with BlockLogs():\n",
    "        return Chem.MolToInchi(mol)\n",
    "\n",
    "df = pd.read_csv(\"./GSK_HepG2.csv\")\n",
    "df = df.iloc[:, 1:]\n",
    "df.columns = ['smiles', 'per_inhibition']\n",
    "df['per_inhibition'] = -df['per_inhibition']\n",
    "\n",
    "\n",
    "# standardize and convert to inchi\n",
    "df['mol'] = df['smiles'].map(standardize)\n",
    "df = df.dropna(subset=['mol'])\n",
    "df['inchi'] = df['mol'].map(mol_to_inchi)\n",
    "df = df.groupby([\"inchi\"]).filter(lambda x: len(x) == 1).reset_index(drop=True)\n",
    "\n",
    "clusters, _ = pd.factorize(\n",
    "    df['mol']\n",
    "        .map(Chem.MolToSmiles) # type: ignore\n",
    "        .map(get_scaffold)\n",
    ")\n",
    "clusters = pd.Series(clusters)\n",
    "\n",
    "\n",
    "df = df.drop(['smiles', 'inchi'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c794f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=1, random_state=RANDOM_SEED)\n",
    "train_idxs, val_test_idxs = next(splitter.split(df, groups=clusters))\n",
    "df_train = df.loc[train_idxs].reset_index(drop=True)\n",
    "df_val_test = df.loc[val_test_idxs].reset_index(drop=True)\n",
    "clusters_val_test = clusters.iloc[val_test_idxs].reset_index(drop=True)\n",
    "\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, random_state=RANDOM_SEED, test_size=0.5)\n",
    "val_idxs, test_idxs = next(splitter.split(df_val_test, groups=clusters_val_test))\n",
    "df_val = df_val_test.loc[val_idxs].reset_index(drop=True)\n",
    "df_test = df_val_test.loc[test_idxs].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afa84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffledPairsDataset(Dataset):\n",
    "    def __init__(self, df, sample_ratio=5):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.sample_ratio = sample_ratio\n",
    "        self.featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "        self.pairs: list = []\n",
    "        self.mg_cache: list = []\n",
    "\n",
    "        self.build_mg_cache()\n",
    "        self.update_pairs()\n",
    "\n",
    "    def build_mg_cache(self):\n",
    "        self.mg_cache = self.df['mol'].map(self.featurizer).tolist()\n",
    "\n",
    "    def update_pairs(self):\n",
    "        N = len(self.df)\n",
    "\n",
    "        weights = self.df['per_inhibition'].to_numpy()\n",
    "        weights = np.where(weights > -15, 8.0, 1.0)\n",
    "        weights = weights / weights.sum()\n",
    "\n",
    "        pairs = [\n",
    "            (i, random.randint(0, N-1))\n",
    "            for i in range(N)\n",
    "            for _ in np.random.choice(\n",
    "                len(df), \n",
    "                size=(5,), \n",
    "                p=weights, \n",
    "                replace=False\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        pairs += [(j, i) for i,j in pairs]\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        left_idx, right_idx = self.pairs[idx]\n",
    "        left_mg, right_mg = self.mg_cache[left_idx], self.mg_cache[right_idx]\n",
    "        delta = (\n",
    "            self.df['per_inhibition'][left_idx] > self.df['per_inhibition'][right_idx]\n",
    "        ).astype(float)\n",
    "\n",
    "        left_datum = data.datasets.Datum(\n",
    "            left_mg, None, None, np.array([delta]), 1.0, None, None\n",
    "        )\n",
    "\n",
    "        right_datum = data.datasets.Datum(\n",
    "            right_mg, None, None, None, 1.0, None, None\n",
    "        )\n",
    "\n",
    "        return [left_datum, right_datum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d03840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExemplarDataset(Dataset):\n",
    "    def __init__(self, df_regular, df_exemplars) -> None:\n",
    "        super().__init__()\n",
    "        self.df_exemplars = df_exemplars\n",
    "        self.df_regular = df_regular\n",
    "        self.featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "        self.pairs = []\n",
    "        self.exemplar_mg_cache: list = []\n",
    "        self.regular_mg_cache: list = []\n",
    "\n",
    "        self.build_pairs()\n",
    "        self.build_mg_cache()\n",
    "\n",
    "    def build_mg_cache(self):\n",
    "        self.exemplar_mg_cache = self.df_exemplars['mol'].map(self.featurizer).tolist()\n",
    "        self.regular_mg_cache = self.df_regular['mol'].map(self.featurizer).tolist()\n",
    "\n",
    "    def build_pairs(self):\n",
    "        self.pairs = [\n",
    "            (i, j)\n",
    "            for i in range(len(self.df_regular))\n",
    "            for j in range(len(self.df_exemplars))\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        regular_idx, exemplar_idx = self.pairs[idx]\n",
    "        regular_mol = self.regular_mg_cache[regular_idx]\n",
    "        exemplar_mol = self.exemplar_mg_cache[exemplar_idx]\n",
    "        delta = (\n",
    "            self.df_regular['per_inhibition'][regular_idx] > \n",
    "            self.df_exemplars['per_inhibition'][exemplar_idx]\n",
    "        ).astype(float)\n",
    "\n",
    "        regular_datum = data.datasets.Datum(\n",
    "            regular_mol, None, None, np.array([delta]), 1.0, None, None\n",
    "        )\n",
    "\n",
    "        exemplar_datum = data.datasets.Datum(\n",
    "            exemplar_mol, None, None, None, 1.0, None, None\n",
    "        )\n",
    "\n",
    "        return [regular_datum, exemplar_datum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac066253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://docs.pytorch.org/docs/stable/notes/randomness.html#dataloader\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "class ConstrastiveDataModule(L.LightningDataModule):\n",
    "    def __init__(self, df_train: pd.DataFrame, df_val: pd.DataFrame):\n",
    "        super().__init__()\n",
    "        self.df_train = df_train\n",
    "        self.df_val = df_val\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = ShuffledPairsDataset(self.df_train, sample_ratio=10)\n",
    "        return DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size=1024,\n",
    "            shuffle=True,\n",
    "            collate_fn=data.dataloader.collate_multicomponent,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=12,\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        exemplar_df = pd.concat([\n",
    "            df_train[df_train['per_inhibition'] > 0].sample(50),\n",
    "            df_train[df_train['per_inhibition'] < 0].sample(50)\n",
    "        ]).reset_index(drop=True)\n",
    "\n",
    "        val_dataset = ExemplarDataset(self.df_val,exemplar_df)\n",
    "        return DataLoader(\n",
    "            dataset=val_dataset,\n",
    "            batch_size=2048,\n",
    "            shuffle=False,\n",
    "            collate_fn=data.dataloader.collate_multicomponent,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=12,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53dcdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdims = featurizers.SimpleMoleculeMolGraphFeaturizer().shape # the dimensions of the featurizer, given as (atom_dims, bond_dims).\n",
    "mcmp = nn.MulticomponentMessagePassing(\n",
    "    blocks=[nn.BondMessagePassing(*fdims), nn.BondMessagePassing(*fdims)],\n",
    "    n_components=2,\n",
    ")\n",
    "agg = nn.NormAggregation()\n",
    "ffn = nn.BinaryClassificationFFN(n_tasks=1, input_dim=mcmp.output_dim)\n",
    "batch_norm = True\n",
    "metric_list = [nn.metrics.BinaryF1Score(), nn.metrics.BinaryAUPRC(), nn.metrics.BinaryAUROC()]\n",
    "mpnn = models.multi.MulticomponentMPNN(mcmp, agg, ffn, batch_norm, metric_list)\n",
    "mpnn.max_lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151275e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "wandb.finish()\n",
    "wandb_logger = WandbLogger(project=\"chemprop_delta_clf\", log_model=\"all\")\n",
    "wandb_logger.experiment.mark_preempting()\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    logger=wandb_logger,\n",
    "    enable_checkpointing=True,  # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=50,  # number of epochs to train for\n",
    "    reload_dataloaders_every_n_epochs=1,\n",
    "    log_every_n_steps=50,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val/prc\", mode=\"max\", verbose=True, patience=10),\n",
    "        ModelCheckpoint(monitor=\"val/prc\", mode=\"max\", save_top_k=2)\n",
    "    ]\n",
    ")\n",
    "\n",
    "contrastive_data_module = ConstrastiveDataModule(df_train, df_val)\n",
    "trainer.fit(mpnn, datamodule=contrastive_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3927e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "run_id = wandb_logger.experiment.id\n",
    "checkpoint_reference = f\"rahul-e-dev/chemprop_delta_clf/model-{run_id}:best\"\n",
    "artifact_dir = wandb_logger.download_artifact(checkpoint_reference, artifact_type=\"model\")\n",
    "\n",
    "\n",
    "ckpt = torch.load(Path(artifact_dir) / \"model.ckpt\", map_location='cpu', weights_only=False)\n",
    "hparams = ckpt.get('hyper_parameters', ckpt.get('hparams', {}))\n",
    "mpnn.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    ")\n",
    "\n",
    "exemplar_df = df_train[df_train['per_inhibition'] > -15].sample(100).reset_index(drop=True)\n",
    "\n",
    "exemplar_ds = ExemplarDataset(\n",
    "    df_test,\n",
    "    exemplar_df\n",
    ")\n",
    "\n",
    "exemplar_dl = DataLoader(\n",
    "    dataset=exemplar_ds,\n",
    "    batch_size=2048,\n",
    "    shuffle=False,\n",
    "    collate_fn=data.dataloader.collate_multicomponent,\n",
    "    num_workers=12,\n",
    ")\n",
    "\n",
    "test_ds_preds = trainer.predict(model=mpnn, dataloaders=exemplar_dl)\n",
    "test_ds_preds = torch.cat(test_ds_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd1b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def calc(x):\n",
    "    x = np.array(x)\n",
    "    return (x>=0.5).sum()\n",
    "\n",
    "\n",
    "deltas = defaultdict(list)\n",
    "for (i, j), delta in zip(exemplar_ds.pairs, test_ds_preds.squeeze()):\n",
    "    exemplar_val = exemplar_ds.df_exemplars['per_inhibition'][j]\n",
    "    deltas[i].append(float(delta.item()))\n",
    "\n",
    "\n",
    "df_test['deltas'] = deltas\n",
    "df_test['pred_probs'] = df_test['deltas'].map(calc)\n",
    "df_test['asd'] = df_test['deltas'].map(np.mean)\n",
    "df_test['preds'] = df_test['pred_probs'] > 3\n",
    "df_test['true'] = df_val['per_inhibition'] > -15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b897f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf934d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "        f1_score(df_test['true'], df_test['preds']),\n",
    "        precision_score(df_test['true'], df_test['preds']),\n",
    "        recall_score(df_test['true'], df_test['preds']),\n",
    "        accuracy_score(df_test['true'], df_test['preds'])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "wandb_logger.log_table(\n",
    "    'final_metrics', \n",
    "    ['f1', 'precision', 'recall', 'accuracy'],\n",
    "    [[\n",
    "        f1_score(df_val['true'], df_val['preds']),\n",
    "        precision_score(df_val['true'], df_val['preds']),\n",
    "        recall_score(df_val['true'], df_val['preds']),\n",
    "        accuracy_score(df_val['true'], df_val['preds'])\n",
    "    ]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88695fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a61707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
