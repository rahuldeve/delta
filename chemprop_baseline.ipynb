{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2befbca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/rahul_e_dev/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.rdBase import BlockLogs\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "from commons.utils import standardize, get_scaffold\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "import lightning as L\n",
    "from chemprop.data.collate import collate_batch\n",
    "from chemprop.data.dataloader import build_dataloader\n",
    "\n",
    "from chemprop import data, featurizers, models, nn\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seeds(RANDOM_SEED)\n",
    "\n",
    "load_dotenv('.env.secret')\n",
    "wandb.login(key='cf344975eb80edf6f0d52af80528cc6094234caf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f70809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_to_inchi(mol):\n",
    "    with BlockLogs():\n",
    "        return Chem.MolToInchi(mol)\n",
    "\n",
    "df = pd.read_csv(\"./GSK_HepG2.csv\")\n",
    "df = df.iloc[:, 1:]\n",
    "df.columns = ['smiles', 'per_inhibition']\n",
    "# df['per_inhibition'] = -df['per_inhibition']\n",
    "\n",
    "\n",
    "# standardize and convert to inchi\n",
    "df['mol'] = df['smiles'].map(standardize)\n",
    "df = df.dropna(subset=['mol'])\n",
    "df['inchi'] = df['mol'].map(mol_to_inchi)\n",
    "df = df.groupby([\"inchi\"]).filter(lambda x: len(x) == 1).reset_index(drop=True)\n",
    "\n",
    "clusters, _ = pd.factorize(\n",
    "    df['mol']\n",
    "        .map(Chem.MolToSmiles) # type: ignore\n",
    "        .map(get_scaffold)\n",
    ")\n",
    "clusters = pd.Series(clusters)\n",
    "\n",
    "\n",
    "df = df.drop(['smiles', 'inchi'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c794f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=1, random_state=RANDOM_SEED)\n",
    "train_idxs, val_test_idxs = next(splitter.split(df, groups=clusters))\n",
    "df_train = df.loc[train_idxs].reset_index(drop=True)\n",
    "df_val_test = df.loc[val_test_idxs].reset_index(drop=True)\n",
    "clusters_val_test = clusters.iloc[val_test_idxs].reset_index(drop=True)\n",
    "\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, random_state=RANDOM_SEED, test_size=0.5)\n",
    "val_idxs, test_idxs = next(splitter.split(df_val_test, groups=clusters_val_test))\n",
    "df_val = df_val_test.loc[val_idxs].reset_index(drop=True)\n",
    "df_test = df_val_test.loc[test_idxs].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3510d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['true'] = (df_train['per_inhibition'] >= 50).astype(float)\n",
    "df_val['true'] = (df_val['per_inhibition'] >= 50).astype(float)\n",
    "df_test['true'] = (df_test['per_inhibition'] >= 50).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b58a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "\n",
    "train_ds = data.MoleculeDataset([\n",
    "    data.MoleculeDatapoint(\n",
    "        df_train['mol'][idx],\n",
    "        y=np.array([df_train['true'][idx]])\n",
    "    )\n",
    "    for idx in range(len(df_train))\n",
    "], featurizer=featurizer)\n",
    "\n",
    "val_ds = data.MoleculeDataset([\n",
    "    data.MoleculeDatapoint(\n",
    "        df_val['mol'][idx],\n",
    "        y=np.array([df_val['true'][idx]])\n",
    "    )\n",
    "    for idx in range(len(df_val))\n",
    "], featurizer=featurizer)\n",
    "\n",
    "\n",
    "test_ds = data.MoleculeDataset([\n",
    "    data.MoleculeDatapoint(\n",
    "        df_test['mol'][idx], \n",
    "        y=np.array([df_test['true'][idx]])\n",
    "    )\n",
    "    for idx in range(len(df_test))\n",
    "], featurizer=featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "171eaaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul_e_dev/delta/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_loader = data.build_dataloader(train_ds, num_workers=12)\n",
    "val_loader = data.build_dataloader(val_ds, num_workers=12, shuffle=False)\n",
    "test_loader = data.build_dataloader(test_ds, num_workers=12, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d53dcdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdims = featurizers.SimpleMoleculeMolGraphFeaturizer().shape # the dimensions of the featurizer, given as (atom_dims, bond_dims).\n",
    "mp = nn.BondMessagePassing()\n",
    "agg = nn.NormAggregation()\n",
    "ffn = nn.BinaryClassificationFFN(n_tasks=1)\n",
    "batch_norm = True\n",
    "metric_list = [nn.metrics.BinaryF1Score(), nn.metrics.BinaryAUPRC(), nn.metrics.BinaryAUROC()]\n",
    "mpnn = models.MPNN(mp, agg, ffn, batch_norm, metric_list)\n",
    "mpnn.max_lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "151275e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20251007_015711-vto37nrv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rahul-e-dev/chemprop_baseline/runs/vto37nrv' target=\"_blank\">expert-river-7</a></strong> to <a href='https://wandb.ai/rahul-e-dev/chemprop_baseline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rahul-e-dev/chemprop_baseline' target=\"_blank\">https://wandb.ai/rahul-e-dev/chemprop_baseline</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rahul-e-dev/chemprop_baseline/runs/vto37nrv' target=\"_blank\">https://wandb.ai/rahul-e-dev/chemprop_baseline/runs/vto37nrv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/home/rahul_e_dev/delta/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name            | Type                    | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | message_passing | BondMessagePassing      | 227 K  | train\n",
      "1 | agg             | NormAggregation         | 0      | train\n",
      "2 | bn              | BatchNorm1d             | 600    | train\n",
      "3 | predictor       | BinaryClassificationFFN | 90.6 K | train\n",
      "4 | X_d_transform   | Identity                | 0      | train\n",
      "5 | metrics         | ModuleList              | 0      | train\n",
      "--------------------------------------------------------------------\n",
      "318 K     Trainable params\n",
      "0         Non-trainable params\n",
      "318 K     Total params\n",
      "1.276     Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29183383d9a647c8959ddabf60a454a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul_e_dev/delta/.venv/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a223424c1e84f82b0fb2e4d9c82fa5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0c567bf20b4a4f9df7a209c1b291ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/prc improved. New best score: 0.580\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87b43179b6c47f8bbcfec1682274010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970d5712dfaf4668ba2287553a701113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8514a3577408485387fd8f5df99f400d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910f5da42fcd4aa28a2e8d3d812c3693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/prc improved by 0.028 >= min_delta = 0.0. New best score: 0.608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651e6e2bc5724b88aaab2d165be0265e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/prc improved by 0.037 >= min_delta = 0.0. New best score: 0.645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13deb4406a4f43bc9e714f189b7f3994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/prc improved by 0.040 >= min_delta = 0.0. New best score: 0.685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da05722d5f24afeabeefaafcce9e6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb1143645cc46d0bf6b77c6e965f7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011d8cf283364778b134454272ab7cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da400a4298834106b1e3d486046e8628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f93b17dfcbb4d32a2abab25d283a8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e7c3acc86a4abfb6908272d5881b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435a941807624da0a7afb92781983614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb29183d2ea4e2fb0f16218b8802125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1700cfb2c8e473aa688c94480852598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72108035b3349bd934d4e69e8bb7789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val/prc did not improve in the last 10 records. Best score: 0.685. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "wandb.finish()\n",
    "wandb_logger = WandbLogger(project=\"chemprop_baseline\", log_model=\"all\", save_code=True)\n",
    "wandb_logger.experiment.mark_preempting()\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    logger=wandb_logger,\n",
    "    enable_checkpointing=True,  # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=50,  # number of epochs to train for\n",
    "    reload_dataloaders_every_n_epochs=1,\n",
    "    log_every_n_steps=50,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val/prc\", mode=\"max\", verbose=True, patience=10),\n",
    "        ModelCheckpoint(monitor=\"val/prc\", mode=\"max\", save_top_k=2)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "trainer.fit(mpnn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3927e3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/rahul_e_dev/delta/.venv/lib/python3.12/site-packages/lightning/pytorch/core/saving.py:363: Skipping 'metrics' parameter because it is not possible to safely dump to YAML.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9e1cf284e84aa7b4bd488d88bda2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "run_id = wandb_logger.experiment.id\n",
    "checkpoint_reference = f\"rahul-e-dev/chemprop_baseline/model-{run_id}:best\"\n",
    "artifact_dir = wandb_logger.download_artifact(checkpoint_reference, artifact_type=\"model\")\n",
    "\n",
    "\n",
    "ckpt = torch.load(Path(artifact_dir) / \"model.ckpt\", map_location='cpu', weights_only=False)\n",
    "hparams = ckpt.get('hyper_parameters', ckpt.get('hparams', {}))\n",
    "mpnn.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    ")\n",
    "\n",
    "test_ds_preds = trainer.predict(model=mpnn, dataloaders=test_loader)\n",
    "test_ds_preds = torch.cat(test_ds_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da5e34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['preds'] = (test_ds_preds.squeeze().numpy() >= 0.5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc4c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "wandb_logger.log_table(\n",
    "    'final_metrics', \n",
    "    ['f1', 'precision', 'recall', 'accuracy'],\n",
    "    [[\n",
    "        f1_score(df_test['true'], df_test['preds']),\n",
    "        precision_score(df_test['true'], df_test['preds']),\n",
    "        recall_score(df_test['true'], df_test['preds']),\n",
    "        accuracy_score(df_test['true'], df_test['preds'])\n",
    "    ]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88695fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▅▅▅▄▄▄▃▃▂▂▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>▄▅▅▆█▆▄▇▃▇▆▂█▃▄▆▇▃▃▂▄▅▂▄▃▃▅▄▃▃▄▄▃▁▃▂▂▆▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val/f1</td><td>▃▄▁▃▅▇▆▇█▇▇█▇▇▇██</td></tr><tr><td>val/prc</td><td>▆▁▃▆▇▇█▇▇▇▇█▇▇█▇▇</td></tr><tr><td>val/roc</td><td>▇▁▅▇▇▇███▇▇██▇▇██</td></tr><tr><td>val_loss</td><td>▃█▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>train_loss_epoch</td><td>0.27285</td></tr><tr><td>train_loss_step</td><td>0.25792</td></tr><tr><td>trainer/global_step</td><td>2753</td></tr><tr><td>val/f1</td><td>0.58824</td></tr><tr><td>val/prc</td><td>0.65572</td></tr><tr><td>val/roc</td><td>0.84468</td></tr><tr><td>val_loss</td><td>0.34161</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">expert-river-7</strong> at: <a href='https://wandb.ai/rahul-e-dev/chemprop_baseline/runs/vto37nrv' target=\"_blank\">https://wandb.ai/rahul-e-dev/chemprop_baseline/runs/vto37nrv</a><br> View project at: <a href='https://wandb.ai/rahul-e-dev/chemprop_baseline' target=\"_blank\">https://wandb.ai/rahul-e-dev/chemprop_baseline</a><br>Synced 8 W&B file(s), 1 media file(s), 22 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251007_015711-vto37nrv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff431f33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
